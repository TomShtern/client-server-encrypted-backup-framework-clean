"""
Enhanced Logs View - Comprehensive log viewing and management.

Organization:
    - Section 1: Data Fetching (async wrappers with run_in_executor)
    - Section 2: Business Logic (pure functions for filtering, calculations)
    - Section 3: UI Components (Flet control builders)
    - Section 4: Event Handlers (user interaction handlers)
    - Section 5: Main View (view composition and setup)
"""

import asyncio
import os
import sys
import logging
import contextlib
from datetime import datetime
import json
import re
import csv
from typing import Any, Callable, Optional
try:
    import websockets
except ImportError:
    websockets = None

import flet as ft

# Path setup
_views_dir = os.path.dirname(os.path.abspath(__file__))
_flet_v2_root = os.path.dirname(_views_dir)
_repo_root = os.path.dirname(_flet_v2_root)
for _path in (_flet_v2_root, _repo_root):
    if _path not in sys.path:
        sys.path.insert(0, _path)

import Shared.utils.utf8_solution as _  # noqa: F401

# Import new utilities
from utils.async_helpers_exp import run_sync_in_executor, fetch_with_loading, debounce
from utils.loading_states import create_loading_indicator, create_error_display, show_success_snackbar
from utils.data_export import export_to_csv, export_to_json, generate_export_filename
from utils.ui_builders import create_search_bar, create_filter_dropdown, create_action_button
from components.filter_controls import FilterControls
from components.log_card import LogCard  # This component already exists

# ------------------------------------------------------------------------------------
# SECTION 1: DATA FETCHING (Async wrappers for ServerBridge calls with proper run_in_executor)
# ------------------------------------------------------------------------------------

async def fetch_logs_async(bridge, filters=None):
    """Fetch logs from server with optional filters."""
    if not bridge:
        return []
    try:
        result = await run_sync_in_executor(bridge.get_logs)
        if isinstance(result, dict) and result.get('success'):
            data = result.get('data', {})
            # Server returns {'logs': [...], 'note': '...'}, extract the logs list
            if isinstance(data, dict):
                raw_logs = data.get('logs', [])
                # Convert raw log strings to dict format
                parsed_logs = []
                for line in raw_logs:
                    if isinstance(line, str):
                        # Parse log line format: "TIMESTAMP - LEVEL - MESSAGE"
                        # Example: "2025-10-10 20:18:34,099 - INFO - Server started"
                        parts = line.split(' - ', 2)
                        if len(parts) >= 3:
                            parsed_logs.append({
                                'time': parts[0].strip(),
                                'level': parts[1].strip(),
                                'message': parts[2].strip(),
                                'component': 'Server',
                            })
                        else:
                            # Fallback for unparseable lines
                            parsed_logs.append({
                                'time': '',
                                'level': 'INFO',
                                'message': line,
                                'component': 'Server',
                            })
                    elif isinstance(line, dict):
                        # Already in dict format
                        parsed_logs.append(line)
                return parsed_logs
            return []
        return []
    except Exception as e:
        logging.error(f"fetch_logs_async failed: {e}")
        import traceback
        traceback.print_exc()
        return []

async def fetch_log_statistics_async(bridge):
    """Fetch log statistics from server."""
    # Placeholder implementation - implement based on actual server API
    # For now, return statistics calculated from the logs themselves
    logs = await fetch_logs_async(bridge)
    return calculate_log_statistics(logs)

async def fetch_available_levels_async(bridge):
    """Fetch available log levels from server."""
    # Placeholder implementation - get levels from logs
    logs = await fetch_logs_async(bridge)
    levels = list(set([log.get('level', 'INFO') for log in logs if 'level' in log]))
    return sorted(levels) if levels else ['INFO', 'ERROR', 'WARNING', 'DEBUG', 'CRITICAL']

# ------------------------------------------------------------------------------------
# SECTION 2: BUSINESS LOGIC (Pure functions for filtering, calculations, exports)
# ------------------------------------------------------------------------------------

def filter_logs_by_query(logs, query):
    """Filter logs by search query (case-insensitive)."""
    if not query or not logs:
        return logs or []

    query_lower = query.lower()
    return [
        log for log in logs
        if query_lower in log.get('message', '').lower()
        or query_lower in log.get('level', '').lower()
        or query_lower in log.get('time', '').lower()
    ]

def filter_logs_by_level(logs, level):
    """Filter logs by log level."""
    if not logs:
        return []
    if level == "All" or not level:
        return logs
    return [log for log in logs if log.get('level') == level]

def calculate_log_statistics(logs):
    """Calculate statistics from log entries."""
    if not logs:
        return {
            'total': 0,
            'by_level': {},
            'by_hour': {},
            'latest': None
        }

    stats = {
        'total': len(logs),
        'by_level': {},
        'by_hour': {},
        'latest': logs[0] if logs else None
    }

    for log in logs:
        level = log.get('level', 'UNKNOWN')
        stats['by_level'][level] = stats['by_level'].get(level, 0) + 1
        
        # Extract hour from timestamp for hourly stats
        if 'time' in log and log['time']:
            try:
                dt = datetime.strptime(log['time'].split(',')[0], "%Y-%m-%d %H:%M:%S")
                hour_key = dt.strftime("%Y-%m-%d %H:00")
                stats['by_hour'][hour_key] = stats['by_hour'].get(hour_key, 0) + 1
            except ValueError:
                # If timestamp format doesn't match, skip hourly stats for this log
                pass

    return stats

def export_logs_to_csv(logs, filepath):
    """Export logs to CSV file."""
    export_to_csv(logs, filepath, fieldnames=['time', 'level', 'message', 'component'])

def export_logs_to_json(logs, filepath):
    """Export logs to JSON file."""
    export_to_json(logs, filepath)

def _compile_search_regex(search_query: str) -> re.Pattern:
    """
    Compile a regex pattern from search query.
    Supports both plain text and regex patterns (enclosed in /pattern/ or /pattern/flags).
    """
    # Guard clause: handle plain text search first
    if not (search_query.startswith('/') and search_query.count('/') >= 2):
        return re.compile(re.escape(search_query), re.IGNORECASE)

    # Extract pattern and flags for regex patterns
    parts = search_query.split('/')
    if len(parts) >= 3:
        pattern = parts[1]
        flags_str = parts[2] if len(parts) > 2 else ''
        # Parse flags
        flags = 0
        if 'i' in flags_str:
            flags |= re.IGNORECASE
        if 'm' in flags_str:
            flags |= re.MULTILINE
        if 's' in flags_str:
            flags |= re.DOTALL

        try:
            return re.compile(pattern, flags)
        except re.error:
            # Invalid regex, fall back to literal search
            return re.compile(re.escape(search_query), re.IGNORECASE)
    else:
        # Malformed regex, treat as literal
        return re.compile(re.escape(search_query), re.IGNORECASE)

def highlight_text_with_search(text: str, search_query: str) -> ft.Control:
    """
    Creates a text control with highlighted search terms.
    Supports both plain text and regex patterns (enclosed in /pattern/ or /pattern/flags).
    Uses optimized regex matching for better performance.
    """
    if not search_query or not text:
        return ft.Text(text, selectable=True, size=12)

    try:
        regex = _compile_search_regex(search_query)
        matches = list(regex.finditer(text))
        if not matches:
            return ft.Text(text, selectable=True, size=12)

        # Build the text with highlighted parts
        spans = []
        last_end = 0
        for match in matches:
            start, end = match.span()
            # Add the text before the match
            if start > last_end:
                spans.append(ft.TextSpan(text[last_end:start]))
            # Add the highlighted match
            spans.append(ft.TextSpan(
                text[start:end],
                style=ft.TextStyle(
                    bgcolor=ft.colors.AMBER_200,
                    color=ft.colors.BLACK
                )
            ))
            last_end = end

        # Add any remaining text after the last match
        if last_end < len(text):
            spans.append(ft.TextSpan(text[last_end:]))

        return ft.SelectableText(spans=spans, size=12)
    except Exception:
        # Fallback to plain text if highlighting fails
        return ft.Text(text, selectable=True, size=12)

# ------------------------------------------------------------------------------------
# SECTION 3: UI COMPONENTS (Flet control builders - pure UI, no business logic)
# ------------------------------------------------------------------------------------

def build_log_card(log_entry, search_query="", theme=None):
    """Build a single log card display."""
    level = log_entry.get('level', 'INFO')
    message = log_entry.get('message', '')
    timestamp = log_entry.get('time', '')
    component = log_entry.get('component', 'Server')

    # Define level colors
    level_colors = {
        'ERROR': ft.colors.ERROR,
        'WARNING': ft.colors.ORANGE,
        'INFO': ft.colors.BLUE,
        'DEBUG': ft.colors.GREY,
        'CRITICAL': ft.colors.RED
    }

    # Use highlighted text if there's a search query
    message_control = (
        highlight_text_with_search(message, search_query) 
        if search_query 
        else ft.Text(message, selectable=True, size=14)
    )

    return ft.Container(
        content=ft.Column([
            ft.Row([
                ft.Container(
                    content=ft.Text(level, color=ft.colors.ON_PRIMARY, size=12, weight=ft.FontWeight.BOLD),
                    bgcolor=level_colors.get(level, ft.colors.PRIMARY),
                    padding=ft.padding.symmetric(horizontal=8, vertical=4),
                    border_radius=4
                ),
                ft.Text(timestamp, size=12, color=ft.colors.ON_SURFACE_VARIANT),
                ft.Text(component, size=12, color=ft.colors.ON_SURFACE_VARIANT),
            ], spacing=10),
            message_control
        ], spacing=8),
        padding=15,
        border_radius=8,
        bgcolor=ft.colors.SURFACE_VARIANT,
        margin=ft.margin.only(bottom=8)
    )

def build_filter_controls(on_search_change, on_level_change, available_levels):
    """Build filter control panel."""
    return ft.Row([
        create_search_bar(on_change=on_search_change, placeholder="Search logs..."),
        create_filter_dropdown(
            label="Level",
            options=["All"] + available_levels,
            on_change=on_level_change
        )
    ], spacing=15)

def build_stats_dashboard(stats):
    """Build statistics dashboard display."""
    if not stats:
        return ft.Container()
        
    return ft.Container(
        content=ft.Column([
            ft.Text(f"Total Logs: {stats['total']}", size=16, weight=ft.FontWeight.BOLD),
            ft.Row([
                ft.Text(f"{level}: {count}", size=14)
                for level, count in stats['by_level'].items()
            ], wrap=True)
        ], spacing=10),
        padding=15,
        border_radius=8,
        bgcolor=ft.colors.SURFACE_VARIANT
    )

# ------------------------------------------------------------------------------------
# SECTION 4: EVENT HANDLERS (User interaction handlers - coordinate between UI and business logic)
# ------------------------------------------------------------------------------------

async def handle_search_changed(e, state, page):
    """Handle search query changes with debouncing."""
    query = e.control.value
    state['search_query'] = query

    # Apply filters
    filtered_logs = filter_logs_by_query(state['all_logs'], query)
    filtered_logs = filter_logs_by_level(filtered_logs, state['selected_level'])

    state['filtered_logs'] = filtered_logs

    # Update UI
    rebuild_log_list(state, page, query)

async def handle_level_changed(e, state, page):
    """Handle log level filter changes."""
    level = e.control.value
    state['selected_level'] = level

    # Apply filters
    filtered_logs = filter_logs_by_query(state['all_logs'], state['search_query'])
    filtered_logs = filter_logs_by_level(filtered_logs, level)

    state['filtered_logs'] = filtered_logs

    # Update UI
    rebuild_log_list(state, page, state['search_query'])

async def handle_export_clicked(e, state, page, format_type):
    """Handle export button clicks."""
    logs = state['filtered_logs']

    if not logs:
        # Use show_error_snackbar once it's properly imported
        page.snack_bar = ft.SnackBar(ft.Text("No logs to export"))
        page.snack_bar.open = True
        page.update()
        return

    filename = generate_export_filename("logs", format_type)

    try:
        if format_type == "csv":
            export_to_csv(logs, filename)
        elif format_type == "json":
            export_to_json(logs, filename)

        show_success_snackbar(page, f"Exported {len(logs)} logs to {filename}")

    except Exception as ex:
        # Use show_error_snackbar once it's properly imported
        page.snack_bar = ft.SnackBar(ft.Text(f"Export failed: {str(ex)}"))
        page.snack_bar.open = True
        page.update()

# ------------------------------------------------------------------------------------
# SECTION 5: MAIN VIEW (View composition and setup - orchestrates everything)
# ------------------------------------------------------------------------------------

def create_logs_view(page, bridge):
    """Create the enhanced logs view with all functionality."""

    # State management
    state = {
        'all_logs': [],
        'filtered_logs': [],
        'search_query': '',
        'selected_level': 'All',
        'available_levels': [],
        'stats': {}
    }

    # UI containers (will be populated)
    log_list_container = ft.Column(scroll=ft.ScrollMode.AUTO, expand=True)
    stats_container = ft.Container()
    loading_indicator_ui = create_loading_indicator("Loading logs...")
    error_display_ui = ft.Container(visible=False)

    # Setup function (loads initial data)
    async def setup():
        """Setup the view with initial data."""
        try:
            # Show loading state
            main_content.content = loading_indicator_ui
            page.update()

            # Fetch data
            levels = await fetch_available_levels_async(bridge)
            logs = await fetch_logs_async(bridge)
            stats = await fetch_log_statistics_async(bridge)

            # Update state
            state['available_levels'] = levels
            state['all_logs'] = logs
            state['filtered_logs'] = logs
            state['stats'] = stats

            # Build UI
            rebuild_log_list(state, page)
            stats_container.content = build_stats_dashboard(stats)

            # Show main content
            main_content.content = main_layout
            page.update()

        except Exception as e:
            error_display_ui.content = create_error_display(str(e))
            error_display_ui.visible = True
            main_content.content = error_display_ui
            page.update()

    # Helper function to rebuild log list
    def rebuild_log_list(state, page, search_query=""):
        """Rebuild log list display."""
        log_list_container.controls.clear()

        for log in state['filtered_logs']:
            log_card = build_log_card(log, search_query, page.theme)
            log_list_container.controls.append(log_card)

        log_list_container.update()

    # Build filter controls
    filter_controls_ui = build_filter_controls(
        on_search_change=lambda e: handle_search_changed(e, state, page),
        on_level_change=lambda e: handle_level_changed(e, state, page),
        available_levels=state['available_levels']
    )

    # Build action buttons
    action_buttons = ft.Row([
        create_action_button("Export CSV", lambda e: handle_export_clicked(e, state, page, "csv"), icon=ft.icons.DOWNLOAD),
        create_action_button("Export JSON", lambda e: handle_export_clicked(e, state, page, "json"), icon=ft.icons.DOWNLOAD, primary=False)
    ], spacing=10)

    # Main layout
    main_layout = ft.Column([
        stats_container,
        ft.Divider(),
        filter_controls_ui,
        action_buttons,
        ft.Divider(),
        log_list_container
    ], expand=True, spacing=15)

    # Main content container
    main_content = ft.Container(content=loading_indicator_ui, expand=True, padding=20)

    # Return view, dispose function, and setup function
    return main_content, lambda: None, setup