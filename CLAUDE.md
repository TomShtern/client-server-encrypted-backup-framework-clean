# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.



## Project Overview

A **4-layer Client-Server Encrypted Backup Framework** implementing secure file transfer with RSA-1024 + AES-256-CBC encryption. The system is fully functional with evidence of successful file transfers in `received_files/`.

### Architecture Layers

1. **Web UI** (`Client/Client-gui/NewGUIforClient.html`) - **ENHANCED MODULAR STRUCTURE** - Professional-grade interface with advanced UI enhancements, tooltip system, form memory, and connection monitoring
2. **Flask API Bridge** (`api_server/cyberbackup_api_server.py`) - **CRITICAL INTEGRATION LAYER** - HTTP API server (port 9090) that coordinates between UI and native client, manages subprocess lifecycles
3. **C++ Client** (`Client/cpp/client.cpp`) - Native encryption engine with binary protocol (runs as subprocess)
4. **Python Server** (`python_server/server/server.py`) - Multi-threaded backup storage server (port 1256)

### Data Flow
```
Web UI ‚Üí Flask API (9090) ‚Üí C++ Client (subprocess) ‚Üí Python Server (1256) ‚Üí File Storage
```

## Essential Commands

### Building the C++ Client
```bash
# CRITICAL: Must use vcpkg toolchain - builds fail without it
cmake -B build -DCMAKE_TOOLCHAIN_FILE="vcpkg/scripts/buildsystems/vcpkg.cmake"

# Build
cmake --build build --config Release

# Output: build/Release/EncryptedBackupClient.exe
```

### Running the System

#### Quick System Startup (RECOMMENDED)
```bash
# Single command to start entire system
python scripts/launch_gui.py
# Starts Flask API server + opens browser to http://localhost:9090/
# Automatically handles port checking and server readiness

python scripts/one_click_build_and_run.py  # Full build + deploy + launch
# Enhanced one-click script with error tracking, process management, and GUI modes
```

#### Manual Service Management
```bash
# 1. Start Python backup server (must start FIRST)
python python_server/server/server.py    # Port 1256

# 2. Start Flask API bridge  
python api_server/cyberbackup_api_server.py    # Port 9090

# 3. Build C++ client (after any C++ changes)
cmake --build build --config Release
```

### System Health Verification
```bash
# Check all services are running
netstat -an | findstr ":9090\|:1256"  # Both ports should show LISTENING
tasklist | findstr "python"           # Should show multiple Python processes

# Monitor system logs and performance
python scripts/monitor_logs.py        # Real-time log monitoring with filtering
python scripts/check_dependencies.py  # Verify all dependencies are installed

# Verify file transfers
dir "received_files"                  # Check for actual transferred files
python scripts/create_test_file.py    # Create test files for verification
```

### Testing & Verification
```bash
# Integration tests (test complete web‚ÜíAPI‚ÜíC++‚Üíserver chain)
python tests/test_gui_upload.py      # Full integration test via GUI API
python tests/test_upload.py          # Direct server test
python tests/test_client.py          # C++ client validation

# Comprehensive test suite
python scripts/testing/master_test_suite.py

# Quick validation
python scripts/testing/quick_validation.py

# Validate specific fixes
python scripts/testing/validate_null_check_fixes.py
python scripts/testing/validate_server_gui.py

# New specialized tests
python scripts/test_emoji_support.py        # Test Unicode/emoji handling
python scripts/test_one_click_dry_run.py    # Test build process without execution
python scripts/test_one_click_fixes.py      # Validate one-click script fixes

# Verify real file transfers (CRITICAL verification pattern)
# Check: received_files/ for actual transferred files
# Pattern: {username}_{timestamp}_{filename}
```

## Critical Operating Knowledge

### Configuration Requirements
- **transfer.info**: Must contain exactly 3 lines: `server:port`, `username`, `filepath`
- **Working Directory**: C++ client MUST run from directory containing `transfer.info`
- **Batch Mode**: Use `--batch` flag to prevent C++ client hanging in subprocess
- **Progress Configuration**: `progress_config.json` defines phase timing, weights, and calibration data

### Development Environment Setup
```bash
# Install Python dependencies
pip install -r requirements.txt

# Required packages (if missing): flask-cors, sentry-sdk, flask-socketio, watchdog, psutil

# Verify vcpkg toolchain is configured
cmake -B build -DCMAKE_TOOLCHAIN_FILE="vcpkg/scripts/buildsystems/vcpkg.cmake"

# Check C++ dependencies are installed via vcpkg
vcpkg list | findstr "boost\|cryptopp\|zlib\|sentry"
```

### Essential Integration Patterns

#### Subprocess Management (CRITICAL PATTERN)
```python
# RealBackupExecutor launches C++ client with --batch mode
self.backup_process = subprocess.Popen(
    [self.client_exe, "--batch"],  # --batch prevents hanging in subprocess
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
    text=True,
    cwd=os.path.dirname(os.path.abspath(self.client_exe))  # CRITICAL: Working directory
)
```

#### Configuration Generation Pattern
```python
# transfer.info must be generated per operation (3-line format)
def _generate_transfer_info(self, server_ip, server_port, username, file_path):
    with open("transfer.info", 'w') as f:
        f.write(f"{server_ip}:{server_port}\n")  # Line 1: server endpoint
        f.write(f"{username}\n")                 # Line 2: username  
        f.write(f"{file_path}\n")                # Line 3: absolute file path
```

#### File Verification Pattern (CRITICAL)
```python
def _verify_file_transfer(self, original_file, username):
    # 1. Check received_files/ for actual file
    # 2. Compare file sizes
    # 3. Compare SHA256 hashes  
    # 4. Verify network activity on port 1256
    verification = {
        'transferred': file_exists_in_server_dir,
        'size_match': original_size == received_size,
        'hash_match': original_hash == received_hash,
        'network_activity': check_port_1256_connections()
    }
```

### Verification Points
- **Success Verification**: Check `received_files/` for actual file transfers (exit codes are unreliable)
- **Port Availability**: Ensure ports 9090 and 1256 are free
- **Dependencies**: Common missing packages include flask-cors, sentry-sdk, flask-socketio, watchdog
- **Hash Verification**: Always compare SHA256 hashes of original vs transferred files
- **Network Activity**: Verify TCP connections to port 1256 during transfers

### Known Issues  
- C++ client hangs without `--batch` flag when run as subprocess
- **False Success**: Zero exit code doesn't guarantee successful transfer
- **Missing Files**: Always verify actual files appear in `received_files/`

### Security Vulnerabilities (Active Issues)
- **Static IV**: Zero IV allows pattern analysis (HIGH PRIORITY)
- **No HMAC**: CRC32 provides no tampering protection (MEDIUM PRIORITY)
- **Deterministic encryption**: Same plaintext produces same ciphertext


## Architecture Details

### Core Components
- **Real Backup Executor** (`src/api/real_backup_executor.py`): Manages C++ client subprocess execution with sophisticated multi-layer progress monitoring
- **Network Server** (`python_server/server/server.py`): Multi-threaded TCP server handling encrypted file transfers  
- **Flask API Bridge** (`api_server/cyberbackup_api_server.py`): HTTP API server with Sentry integration for error tracking
- **Crypto Wrappers** (`Client/wrappers/`): RSA/AES encryption abstractions for C++ client
- **Protocol Implementation**: 23-byte binary headers + encrypted payload with CRC32 verification
- **Shared Utilities** (`Shared/`): Common utilities including observability, logging, file lifecycle management, error handling, and process monitoring
- **Observability Framework** (`Shared/observability.py`): Comprehensive structured logging with metrics collection, system monitoring, and timed operation tracking
- **Progress Monitoring System**: Multi-layer progress tracking with StatisticalProgressTracker, TimeBasedEstimator, BasicProcessingIndicator, and DirectFilePoller
- **WebSocket Broadcasting**: Real-time progress updates via SocketIO with enhanced job management and cancellation support
- **UI Enhancement Suite** (`Client/Client-gui/scripts/managers/`): Professional UI components including TooltipManager, FormMemoryManager, ConnectionHealthMonitor, and enhanced ErrorBoundary

### Key Integration Points
- **Subprocess Communication**: Flask API ‚Üí RealBackupExecutor ‚Üí C++ client (with `--batch` flag)
- **File Lifecycle**: SynchronizedFileManager prevents race conditions in file creation/cleanup
- **Progress Flow**: RealBackupExecutor.status_callback ‚Üí API server status_handler ‚Üí WebSocket socketio.emit ‚Üí Web GUI
- **Error Propagation**: C++ client logs ‚Üí subprocess stdout ‚Üí RealBackupExecutor ‚Üí Flask API ‚Üí Web UI
- **Configuration**: Centralized through `transfer.info` and `progress_config.json`
- **WebSocket Broadcasting**: Real-time progress updates via SocketIO with CallbackMultiplexer for concurrent request routing
- **File Receipt Override**: FileReceiptProgressTracker provides ground truth completion by monitoring actual file data
- **UI Enhancement Integration**: TooltipManager for rich hover information, FormMemoryManager for persistent settings, ConnectionHealthMonitor for real-time network feedback

### Security Considerations
- **Current Encryption**: RSA-1024 + AES-256-CBC (functional but has known vulnerabilities)
- **Vulnerabilities**: 
  - ‚ö†Ô∏è **Fixed IV Issue**: Static zero IV allows pattern analysis (HIGH PRIORITY FIX)
  - ‚ö†Ô∏è **CRC32 vs HMAC**: No tampering protection (MEDIUM PRIORITY FIX)
  - **Deterministic encryption**: Same plaintext produces same ciphertext
- **Access Control**: Basic username-based identification (not true authentication)
- **Protocol Implementation**: Custom TCP protocol with 23-byte headers + encrypted payload
- **Key Management**: RSA-1024 for key exchange (Crypto++ with OAEP padding), AES-256-CBC for file encryption

### Development Workflow
1. Always verify file transfers by checking `received_files/` directory
2. Use `--batch` flag for all C++ client subprocess calls
3. Test complete integration chain through all 4 layers
4. Monitor ports 9090 and 1256 for conflicts
5. Check both `build/Release/` and `client/` directories for executables

## Current System Status

**‚úÖ FULLY OPERATIONAL** - All 4 architectural layers working together
- 72+ successful file transfers confirmed in `received_files/`
- Complete UTF-8 support for international filenames
- Modular web client with professional UI enhancements
- Zero import errors across all critical modules




## UTF-8 Unicode Support

**Complete solution** for international filenames and content across the entire project.

### Quick Implementation
```python
# Entry point scripts - add this ONE line:
import Shared.utils.utf8_solution  # Auto-enables UTF-8 for all subprocess operations

# Now all subprocess calls use UTF-8 automatically:
import subprocess
result = subprocess.run([exe, "--batch"], capture_output=True)  # Hebrew+emoji works!
```

### Core Components
- **`Shared/utils/utf8_solution.py`** - Main UTF-8 solution
- **Windows console** automatically set to UTF-8 (Code Page 65001)
- **Environment variables** configured: `PYTHONIOENCODING=utf-8`, `PYTHONUTF8=1`
- **Enhanced functions**: `run_utf8()`, `Popen_utf8()`, `get_env()`

### Usage Pattern
```python
# For entry point scripts:
import Shared.utils.utf8_solution  # ONE import enables UTF-8 for entire session

# For library/worker files:
# NO imports needed - inherits UTF-8 from entry point
```

### Key Benefits
- Hebrew filenames with emojis work: `◊ß◊ï◊ë◊•_◊¢◊ë◊®◊ô_üéâ_test.txt`
- Zero encoding errors in production
- Backward compatible - no changes to existing code
- Automatic subprocess UTF-8 compliance


## Quick Troubleshooting Guide

### Common Issues & Solutions

#### System Won't Start
  usually its a problem with the code.

#### "Connection Refused" in Browser
- **Issue**: Flask API server (port 9090) not running
- **Solution**: Check both servers are running: NOTE that when you are changing code, the api server will close it self.  `tasklist | findstr "python"`
- **Windows TIME_WAIT**: Wait 30-60 seconds if recently restarted, or use cleanup commands above


#### File Transfers Fail
- **Verify endpoint**: Check `received_files/` for actual files (exit codes are unreliable)
- **Protocol issues**: Ensure using latest `build/Release/EncryptedBackupClient.exe`
- **Configuration**: Verify `transfer.info` has exactly 3 lines: `server:port`, `username`, `filepath`


#### Build Failures
- **vcpkg required**: Must use `cmake -B build -DCMAKE_TOOLCHAIN_FILE="vcpkg/scripts/buildsystems/vcpkg.cmake"`
- **Missing dependencies**: Run `pip install -r requirements.txt` (flask-cors commonly missing)

### Emergency Recovery
```bash
# Complete system reset
taskkill /f /im python.exe
taskkill /f /im EncryptedBackupClient.exe
del transfer.info
python one_click_build_and_run.py
```

## Critical Race Condition Analysis

### **RESOLVED: Global Singleton Race Condition (Root Cause of Progress Issues)**

**Problem**: The API server uses a global singleton `backup_executor` shared across all concurrent requests, causing progress updates to be routed to the wrong clients.

**Code Location**: `cyberbackup_api_server.py:40`
```python
# Global singleton shared across ALL requests - DANGEROUS!
backup_executor = RealBackupExecutor()
```

**Race Scenario**:
1. **Request A** starts backup, sets `backup_executor.set_status_callback(status_handler_A)`
2. **Request B** starts simultaneously, overwrites with `backup_executor.set_status_callback(status_handler_B)`
3. **Request A's progress updates** now go to Request B's WebSocket/job_id
4. **Result**: Progress confusion, lost updates, wrong client notifications

**Impact**:
- Progress updates go to wrong clients
- Lost progress updates when callbacks get overwritten
- WebSocket broadcasting confusion
- Multi-user backup interference

**‚úÖ SOLUTION IMPLEMENTED**: CallbackMultiplexer system routes progress callbacks to correct job handlers:
- Maintains per-job handlers in thread-safe dictionary
- Routes progress updates to all active job handlers
- Eliminates race condition by multiplexing instead of overwriting callbacks
- Preserves global singleton while fixing concurrency issues

### **MEDIUM: Thread Proliferation in File Monitor**

**Problem**: File receipt monitor creates unlimited monitoring threads (one per received file) without resource limits.

**Code Location**: `src/server/file_receipt_monitor.py:52-58`
```python
# One thread per file - no limits!
stability_thread = threading.Thread(target=self._monitor_file_stability, ...)
stability_thread.start()
```

**Solution Required**: Implement thread pool or concurrent file monitoring limits

### **FIXED: File Monitor Thread Safety**

**Status**: ‚úÖ **RESOLVED** - Current implementation has proper locking
- Uses `threading.Lock()` with consistent `with self.monitoring_lock:` patterns
- File was completely rewritten in commit `d2dd37b` with thread safety from the start
- Previous analyses claiming locking issues are outdated

## Repository Management

### Current Repository Setup
- **Primary Repository**: `client-server-encrypted-backup-framework-clean` - All active development (45 commits pushed)
- **Original Repository**: `client-server-encrypted-backup-framework` - Minimal original version
- **Current Branch**: `clean-main` (tracking clean-origin/clean-main)

### Handling Workplace-Specific Files
**Important**: Workplace-specific configuration files (`.mcp.json`, `.gemini/settings.json`) are:
- **Kept locally** for functionality (important for workplace tools)
- **Excluded from git** via `.gitignore` to prevent accidental commits  
- **Removed from git history** using `git filter-branch` for clean repository

### Secret Management Protocol
If GitHub secret scanning blocks pushes:
1. **Files are already excluded** via `.gitignore` 
2. **Use git filter-branch** to remove from history: 
   ```bash
   git filter-branch --force --index-filter "git rm --cached --ignore-unmatch .mcp.json .gemini/settings.json || true" --prune-empty HEAD~45..HEAD
   ```
3. **Reference**: `working with protection.md` contains GitHub's official documentation
4. **Alternative**: Use GitHub's bypass URL if secrets are safe to include

## Binary Protocol & Security Implementation

### Custom TCP Protocol (Port 1256)
- **Protocol Version**: 3 (both client and server)
- **Request Codes**: `REQ_REGISTER(1025)`, `REQ_SEND_PUBLIC_KEY(1026)`, `REQ_SEND_FILE(1028)`
- **Response Codes**: `RESP_REG_OK(1600)`, `RESP_PUBKEY_AES_SENT(1602)`, `RESP_FILE_CRC(1603)`
- **Header Format**: 23-byte requests, 7-byte responses (little-endian)
- **CRC Verification**: Linux `cksum` compatible CRC32 algorithm

### Web Client Architecture (8000+ Line Single-File SPA)
```javascript
// Class hierarchy for modular JavaScript application
class App {
    constructor() {
        this.apiClient = new ApiClient();           // Flask API communication
        this.system = new SystemManager();          // Core system management
        this.buttonStateManager = new ButtonStateManager();  // UI state
        this.particleSystem = new ParticleSystem(); // Visual effects
        this.errorBoundary = new ErrorBoundary(this); // Error handling
        // + 10 more manager classes
    }
}
```

### Integration Testing Pattern (CRITICAL)
```python
# Always test the complete web‚ÜíAPI‚ÜíC++‚Üíserver chain
def test_full_backup_chain():
    1. Start backup server (python src/server/server.py)
    2. Start API server (python cyberbackup_api_server.py)  
    3. Create test file with unique content
    4. Upload via /api/start_backup
    5. Monitor process execution and logs
    6. Verify file appears in received_files/
    7. Compare file hashes for integrity
    8. Check network activity and exit codes
```

**Essential Truth**: Component isolation testing misses critical integration issues. Real verification happens through actual file transfers and hash comparison, not just API responses or exit codes.

## Quick Reference Commands
```bash
# Check system health
netstat -an | findstr ":9090\|:1256"    # Port availability
tasklist | findstr "python\|Encrypted"   # Process status

# Emergency cleanup
taskkill /f /im python.exe               # Kill Python processes
taskkill /f /im EncryptedBackupClient.exe # Kill C++ client

# Verify file transfers  
dir "received_files"              # Check received files
python -c "import hashlib; print(hashlib.sha256(open('file.txt','rb').read()).hexdigest())"

# Build troubleshooting
cmake --version                          # Check CMake version
vcpkg list                              # Check installed packages
```

## Latest Integration Status (2025-08-12)

### ‚úÖ CRITICAL FIXES COMPLETED
**System Integration Validated - All Components Working**

**Fixed Integration Issues:**
- ‚ùå `get_file_receipt_monitor()` function was missing ‚Üí ‚úÖ **FIXED**: Updated API server to use global `file_monitor` object
- ‚ùå UnifiedFileMonitor callback mismatch ‚Üí ‚úÖ **FIXED**: Enhanced to support dual callbacks (`completion_callback`, `failure_callback`) with legacy compatibility
- ‚ùå Missing API methods ‚Üí ‚úÖ **FIXED**: Added `check_file_receipt()`, `list_received_files()`, `get_monitoring_status()` methods
- ‚ùå Syntax error in real_backup_executor.py ‚Üí ‚úÖ **FIXED**: Corrected corrupted method definition

**System Validation Results:**
```
[OK] UnifiedFileMonitor import: SUCCESS
[OK] API Server import: SUCCESS  
[OK] RealBackupExecutor import: SUCCESS
[OK] Received files directory: 67 files found
Status: System is OPERATIONAL and READY
```

**Evidence of Production Usage:**
- **67 successful file transfers** confirmed in `received_files/` directory
- Multiple file types validated: `.txt`, `.md`, `.html`, `.docx`
- All architectural layers working seamlessly together
- Zero import errors across all critical modules

### üéØ NEXT PRIORITIES (Based on Refactoring Report) 

**IMMEDIATE (Week 1):**
- Address critical security vulnerabilities (static IV, HMAC implementation)
- Expand test coverage for refactored components

**MEDIUM TERM (Month 1-2):**
- Break down monolithic modules (`cyberbackup_api_server.py`, `ServerGUI.py`) 
- Centralize scattered configuration settings

**ONGOING:**
- Performance optimization leveraging unified architecture
- Documentation updates reflecting refactoring improvements

## Additional Resources

### Technical Implementation Details
- **`UI_Enhancement_Documentation.md`**: **NEW** - Comprehensive documentation for the professional UI enhancement suite including tooltips, form memory, connection monitoring, and error management
- **`UI_Enhancement_Progress_Report.md`**: **NEW** - Complete progress report of 20/23 enhancements completed with technical achievements and metrics
- **`refactoring_report.md`**: Comprehensive refactoring work completed, technical debt analysis, and next steps
- **`Shared/unified_monitor.py`**: New unified file monitoring system replacing dual monitoring architecture
- **`.github/copilot-instructions.md`**: In-depth subprocess management patterns, binary protocol specifications, and security implementation details
- **Evidence of Success**: Check `received_files/` directory for actual file transfers (67 files demonstrate active production usage)
- **`working with protection.md`**: GitHub's official guide for handling secret scanning push protection

## File Receipt Override System (NEW 2025-08-03)

The **FileReceiptProgressTracker** provides ground truth progress completion by monitoring the server's file storage directory in real-time.

### Key Features

1. **Real-Time File Monitoring**: Uses watchdog library with polling fallback for Windows compatibility
2. **File Stability Detection**: Ensures files are completely written before signaling completion
3. **Progress Override**: Immediately signals 100% completion when file appears on server
4. **Ground Truth Verification**: Overrides all other progress estimates with actual file presence

### How It Works

```
File Transfer ‚Üí File Appears in received_files/ ‚Üí FileReceiptProgressTracker detects file ‚Üí 
Verifies file stability ‚Üí Triggers override signal ‚Üí RobustProgressMonitor forces 100% completion ‚Üí 
Web GUI immediately shows "‚úÖ File received on server - Backup complete!"
```

### Critical Fix (2025-08-03)

**Issue**: FileReceiptProgressTracker was monitoring wrong directory (`src\server\received_files`) while server saves files to project root (`received_files`), causing progress to never reach 100%.

**Solution**: Updated monitoring path to match server's actual file storage location:
```python
self.server_received_files = "received_files"  # Server saves files to project root/received_files
```

### Technical Implementation

- **Location**: `src/api/real_backup_executor.py` (FileReceiptProgressTracker class, lines 473-663)
- **Priority**: Highest priority tracker (layer 0) in RobustProgressMonitor
- **Override Mechanism**: Returns `{"progress": 100, "override": True}` when file detected
- **Integration**: Connected through CallbackMultiplexer for proper routing to all job handlers
- **Failsafe Design**: Provides completion signal even if other progress trackers fail

### Benefits

- **Eliminates False Negatives**: File on server = 100% complete, regardless of progress estimation errors
- **User Confidence**: Immediate visual confirmation when backup actually succeeds
- **Debugging Aid**: Clearly distinguishes between transfer completion and progress tracking issues
- **Robust Fallback**: Works even when C++ client output parsing fails